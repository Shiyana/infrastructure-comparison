<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Infrastructure Comparison</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f8fb;
      margin: 0;
      padding: 20px;
      color: #333;
    }
    h1, h2 {
      color: #005792;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 20px;
      background-color: #fff;
    }
    th, td {
      padding: 12px;
      border: 1px solid #ddd;
      text-align: left;
    }
    th {
      background-color: #005792;
      color: white;
    }
    tr:nth-child(even) {
      background-color: #f1f1f1;
    }
    .section {
      margin-bottom: 40px;
    }
    ul {
      line-height: 1.8;
    }
    footer {
      font-size: 0.9em;
      color: #555;
      border-top: 1px solid #ccc;
      padding-top: 10px;
      margin-top: 40px;
    }
  </style>
</head>
<body>

  <h1>üåê Infrastructure Comparison</h1>
  <p><strong>Traditional vs Enterprise vs AI Infrastructure</strong></p>

  <div class="section">
    <h2>üìä Feature Comparison</h2>
    <table>
      <thead>
        <tr>
          <th>Feature</th>
          <th>Traditional Infrastructure</th>
          <th>Enterprise Infrastructure</th>
          <th>AI Infrastructure</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Definition</td>
          <td>Legacy on-prem IT</td>
          <td>Digitized core operations</td>
          <td>AI/ML-centric, high performance</td>
        </tr>
        <tr>
          <td>Compute</td>
          <td>CPUs</td>
          <td>Virtualized CPUs, cloud VMs</td>
          <td>GPUs, TPUs, custom accelerators</td>
        </tr>
        <tr>
          <td>Storage</td>
          <td>HDDs, NAS</td>
          <td>SAN/NAS, cloud, backups</td>
          <td>SSD, NVMe, object storage</td>
        </tr>
        <tr>
          <td>Networking</td>
          <td>LAN</td>
          <td>Redundant, load-balanced</td>
          <td>100GbE, Infiniband, NVLink</td>
        </tr>
        <tr>
          <td>Power & Cooling</td>
          <td>Standard UPS, HVAC</td>
          <td>Dual power feeds, CRAC cooling</td>
          <td>High-density liquid cooling, 30‚Äì60kW racks</td>
        </tr>
        <tr>
          <td>Cost Estimate</td>
          <td>Low CAPEX, stable OPEX</td>
          <td>Medium-high, depending on services</td>
          <td>High initial cost, variable GPU usage cost</td>
        </tr>
        <tr>
          <td>Energy Consumption</td>
          <td>~2‚Äì5 kW/rack</td>
          <td>~8‚Äì15 kW/rack</td>
          <td>~25‚Äì60+ kW/rack (AI pods)</td>
        </tr>
        <tr>
          <td>Security</td>
          <td>Antivirus, firewall</td>
          <td>IAM, encryption, auditing</td>
          <td>Secure enclaves, data lineage, AI audit logs</td>
        </tr>
        <tr>
          <td>Deployment</td>
          <td>Fully on-prem</td>
          <td>Hybrid (on-prem + cloud)</td>
          <td>Hybrid/Multi-cloud, edge AI integration</td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="section">
    <h2>üß™ Technologies by Infrastructure Type</h2>
    <ul>
      <li><strong>Traditional:</strong> VMware, Hyper-V, LAN, bare-metal servers</li>
      <li><strong>Enterprise:</strong> Azure Stack, AWS Outposts, Red Hat, SAP, Oracle, ServiceNow</li>
      <li><strong>AI:</strong> NVIDIA DGX, Google TPUs, LLMOps, Kubeflow, MLFlow, Apache Airflow, Vector Databases (Pinecone, Weaviate)</li>
    </ul>
  </div>

  <div class="section">
    <h2>‚ö° Power & Cost Considerations</h2>
    <ul>
      <li><strong>Traditional Infra:</strong> ~2‚Äì5 kW/rack, $10K‚Äì$30K annual OPEX</li>
      <li><strong>Enterprise Infra:</strong> ~8‚Äì15 kW/rack, costs depend on licensing and scaling strategy</li>
      <li><strong>AI Infra:</strong> GPU clusters require 30‚Äì60kW+ per rack, high cooling demand, cost can exceed $100K/year per GPU pod</li>
    </ul>
  </div>

  <div class="section">
    <h2>üåü Modern AI Trends</h2>
    <ul>
      <li>üîó AI model orchestration: <strong>Kubeflow</strong>, <strong>LLMOps</strong></li>
      <li>üì¶ AI platform stacks: <strong>NVIDIA AI Enterprise</strong>, <strong>Hugging Face Inference API</strong></li>
      <li>üåä Cooling innovations: <strong>Liquid immersion</strong>, <strong>rear-door heat exchangers</strong></li>
      <li>üß† Specialized silicon: <strong>Graphcore IPU</strong>, <strong>GroqChip</strong>, <strong>Cerebras Wafer Scale</strong></li>
      <li>üß© Modular AI platforms: support for MLOps, explainability, AI observability</li>
    </ul>
  </div>

  <footer>
    <p><em>Created by Shiyana Jayanesan Shylaja ‚Äî 2025</em></p>
    <p><a href="https://github.com/Shiyana/infrastructure-comparison">View on GitHub</a></p>
  </footer>

</body>
</html>
